name: Docs Compliance (Hybrid-Methodik)
on:
  pull_request:
    paths:
      - 'docs/planung/**'
      - '.github/workflows/docs-compliance.yml'

permissions:
  contents: read
  pull-requests: write

jobs:
  compliance:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Run compliance analysis
        id: analyze
        run: |
          python3 - << 'PY' > compliance_report.json
          import os, re, json, pathlib

          # --- YAML Front-Matter Reader mit Fallback ---
          def parse_simple_yaml_block(block: str):
              fm = {}
              current_key = None
              for raw in block.splitlines():
                  line = raw.rstrip()
                  if not line.strip():
                      continue
                  m = re.match(r'^([A-Za-z0-9_\-]+):\s*(.*)', line)
                  if m:
                      key, val = m.group(1).strip(), m.group(2).strip()
                      if val == "":
                          fm[key] = []
                          current_key = key
                      else:
                          fm[key] = val.strip().strip('"\'')
                          current_key = None
                      continue
                  if current_key and line.lstrip().startswith('- '):
                      fm[current_key].append(line.lstrip()[2:].strip().strip('"\''))
              return fm

          def read_front_matter(p: pathlib.Path):
              try:
                  txt = p.read_text(encoding='utf-8', errors='ignore')
              except Exception:
                  return {}
              txt = txt.lstrip()
              if not txt.startswith('---'):
                  return {}
              parts = txt.split('---', 2)
              if len(parts) < 3:
                  return {}
              block = parts[1]
              # Try PyYAML first
              try:
                  import yaml
                  fm = yaml.safe_load(block) or {}
                  if isinstance(fm, dict):
                      return fm
              except Exception:
                  pass
              # Fallback: simple parser with list support
              return parse_simple_yaml_block(block)

          # --- Settings ---
          ROOT = pathlib.Path("docs/planung/features-neu")
          MODULES = ["02_neukundengewinnung","03_kundenmanagement"]

          CORE_DIRS = {"backend","frontend","shared","analyse","artefakte"}
          STUB_DIRS = {"lead-erfassung","email-posteingang","kampagnen","implementation-plans",
                       "diskussionen","test-coverage","testing","postmortem"}
          ALLOWED_ROOT_FILES = {"_index.md","SPRINT_MAP.md","technical-concept.md","README.md"}
          IGNORE_FILES = {".DS_Store"}

          def is_stub_dir(modpath: pathlib.Path, dname: str):
              d = modpath / dname
              if not d.is_dir():
                  return False, "not_dir"
              subdirs = [p for p in d.iterdir() if p.is_dir()]
              if subdirs:
                  return False, "has_subdirs"
              md_files = list(d.glob("*.md"))
              if not md_files:
                  return False, "no_md_files"
              for f in md_files:
                  fm = read_front_matter(f)
                  if not (fm.get("doc_type") == "stub" or fm.get("status") == "moved"):
                      return False, f"non_stub_file:{f.name}"
              return True, "ok"

          def check_readme_redirect(modpath: pathlib.Path):
              # README case-insensitive
              candidates = [p for p in [modpath/"README.md", modpath/"readme.md"] if p.exists()]
              if not candidates:
                  return True, "absent"
              p = candidates[0]
              fm = read_front_matter(p)
              ok = (fm.get("doc_type") == "stub" and str(fm.get("moved_to")) in ("./_index.md","_index.md"))
              return ok, "redirect_ok" if ok else "redirect_missing_or_wrong"

          def pattern_frontmatter_issues(modpath: pathlib.Path, module_name: str):
              issues = []
              af = modpath / "artefakte"
              if af.is_dir():
                  for p in af.glob("*_PATTERN.md"):
                      fm = read_front_matter(p)
                      missing = [k for k in ["module","domain","doc_type","status","owner","updated"] if not fm.get(k)]
                      if missing:
                          issues.append({"path": str(p.relative_to(modpath)), "missing": missing})
              return issues

          def required_files_present(modpath: pathlib.Path):
              req = {"_index.md","SPRINT_MAP.md","technical-concept.md"}
              present = {f for f in req if (modpath/f).exists()}
              missing = sorted(req - present)
              return len(missing)==0, missing

          def find_misplaced_analysis_docs(modpath: pathlib.Path):
              # Nur Dateinamen im Modul-ROOT checken (keine Inhalte)
              misplaced = []
              for p in modpath.glob("*"):
                  if p.is_file() and p.suffix.lower()==".md":
                      name = p.name
                      if name in {"_index.md","SPRINT_MAP.md","technical-concept.md","README.md"}:
                          continue
                      if re.search(r"ANALYSE", name, re.IGNORECASE) or name == "VERZEICHNISSTRUKTUR_ANALYSE.md":
                          misplaced.append(name)
              return misplaced

          def resolve_entry_point(ep: str):
              """Versuche mehrere sinnvolle Aufl√∂sungen relativ zu docs/planung/."""
              base = pathlib.Path("docs/planung")
              ep_clean = ep.lstrip("./")
              candidates = [
                  base / ep_clean,                        # exakt
                  base / (ep_clean.rstrip("/")),          # ohne trailing slash
                  base / (ep_clean.rstrip("/")) / "_index.md",  # Verzeichnis ‚Üí _index.md
              ]
              for c in candidates:
                  if c.exists():
                      return c
              return None

          def analyze_triggers():
              base = pathlib.Path("docs/planung")
              out = {}
              for fn in ["TRIGGER_SPRINT_2_1.md","TRIGGER_SPRINT_2_1_1.md"]:
                  p = base/fn
                  if not p.exists():
                      out[fn] = {"exists": False}
                      continue
                  txt = p.read_text(encoding="utf-8", errors="ignore").lstrip()
                  if not txt.startswith("---"):
                      out[fn] = {"exists": True, "has_yaml_header": False}
                      continue
                  fm = read_front_matter(p)
                  eps = fm.get("entry_points") or []
                  ok = True
                  missing = []
                  for ep in eps:
                      r = resolve_entry_point(str(ep))
                      if r is None:
                          ok = False
                          missing.append(ep)
                  out[fn] = {
                      "exists": True,
                      "has_yaml_header": True,
                      "fields_present": [k for k in ("sprint_id","module_focus","entry_points","updated") if k in fm],
                      "entry_points_ok": ok,
                      "entry_points_missing": missing
                  }
              return out

          def analyze_module(module: str):
              modpath = ROOT / module
              root_dirs = sorted([p.name for p in modpath.iterdir() if p.is_dir()])
              root_files = sorted([p.name for p in modpath.iterdir() if p.is_file()])

              result = {
                  "root_dirs": root_dirs,
                  "root_files": root_files,
                  "required_files": {},
                  "readme_redirect_ok": None,
                  "pattern_frontmatter_issues": [],
                  "unexpected_root_dirs": [],
                  "unexpected_root_files": [],
                  "stub_dirs_status": {},
                  "legacy_planning_has_index": None,
              }

              # 1) Verzeichnis-Klassifizierung
              for d in root_dirs:
                  if d in CORE_DIRS or d == "legacy-planning":
                      continue
                  elif d in STUB_DIRS:
                      ok, why = is_stub_dir(modpath, d)
                      result["stub_dirs_status"][d] = {"ok": ok, "why": why}
                      if not ok:
                          result["unexpected_root_dirs"].append({"name": d, "reason": f"stub_violation:{why}"})
                  elif d.startswith("."):
                      # versteckte Verzeichnisse als Hinweis, aber kein harter Blocker
                      result["unexpected_root_dirs"].append({"name": d, "reason": "hidden_dir_in_root"})
                  else:
                      result["unexpected_root_dirs"].append({"name": d, "reason": "not_allowed_in_root"})

              # 2) Pflicht-Dateien
              ok_req, missing = required_files_present(modpath)
              result["required_files"]["ok"] = ok_req
              result["required_files"]["missing"] = missing

              # 3) README Redirect
              ok_rd, why = check_readme_redirect(modpath)
              result["readme_redirect_ok"] = ok_rd
              if not ok_rd:
                  result.setdefault("violations", []).append(f"readme_redirect:{why}")

              # 4) Pattern Front-Matter
              pfm = pattern_frontmatter_issues(modpath, module)
              result["pattern_frontmatter_issues"] = pfm
              if pfm:
                  result.setdefault("violations", []).append("pattern_frontmatter_issues")

              # 5) Fehlplatzierte Analyse-Dokumente (nur Root)
              misplaced = find_misplaced_analysis_docs(modpath)
              result["misplaced_analysis_docs"] = misplaced
              if misplaced:
                  result.setdefault("violations", []).append("analysis_docs_in_root")

              # 6) Unerlaubte Root-Dateien
              for f in root_files:
                  if f in IGNORE_FILES:
                      continue
                  if f not in ALLOWED_ROOT_FILES:
                      result["unexpected_root_files"].append(f)

              # 7) legacy-planning Index-Hinweis
              if "legacy-planning" in root_dirs:
                  result["legacy_planning_has_index"] = (modpath/"legacy-planning/_index.md").exists()

              # 8) 8-Items-Regel (mit Stub-Ausnahme)
              disallowed_dirs = [d for d in root_dirs if (d not in CORE_DIRS and d != "legacy-planning" and d not in STUB_DIRS and not d.startswith("."))]
              passes_dirs = (len(disallowed_dirs) == 0)
              disallowed_files = [f for f in root_files if (f not in ALLOWED_ROOT_FILES and f not in IGNORE_FILES)]
              passes_files = (len(disallowed_files) == 0)
              passes_8_rule = passes_dirs and passes_files and ok_req
              result["passes_8_items_rule"] = passes_8_rule
              if not passes_dirs:
                  result.setdefault("violations", []).append({"unexpected_root_dirs": disallowed_dirs})
              if not passes_files:
                  result.setdefault("violations", []).append({"unexpected_root_files": disallowed_files})

              # overall ok
              ok = passes_8_rule and ok_rd and ok_req and not pfm and not misplaced
              result["ok"] = ok
              return result

          # --- Build report ---
          report = {
              "ref": os.popen("git rev-parse --abbrev-ref HEAD").read().strip(),
              "commit": os.popen("git rev-parse --short HEAD").read().strip(),
              "modules": {},
              "triggers": analyze_triggers(),
          }

          for m in MODULES:
              report["modules"][m] = analyze_module(m)

          summary = {}
          for m, data in report["modules"].items():
              viol = []
              if not data["passes_8_items_rule"]: viol.append("8_items_rule")
              if not data["required_files"]["ok"]: viol.append("required_files")
              if not data["readme_redirect_ok"]: viol.append("readme_redirect")
              if data["pattern_frontmatter_issues"]: viol.append("pattern_frontmatter")
              if data["misplaced_analysis_docs"]: viol.append("analysis_docs_in_root")
              if data.get("unexpected_root_dirs"): viol.append("unexpected_root_dirs")
              if data.get("unexpected_root_files"): viol.append("unexpected_root_files")
              summary[m] = {"ok": data["ok"], "violations": viol}

          report["compliance_summary"] = summary
          print(json.dumps(report, indent=2, ensure_ascii=False))
          PY
          echo "analysis_completed=true" >> $GITHUB_OUTPUT

      - name: Save report
        uses: actions/upload-artifact@v4
        with:
          name: docs-compliance-report-${{ github.run_number }}
          path: compliance_report.json
        if: steps.analyze.outputs.analysis_completed == 'true'

      - name: Check violations
        id: check_violations
        if: steps.analyze.outputs.analysis_completed == 'true'
        run: |
          python3 -c "
          import json, os
          with open('compliance_report.json') as f:
              r = json.load(f)
          violations = [k for k,v in r.get('compliance_summary',{}).items() if not v.get('ok')]
          if violations:
              print(f'‚ùå Compliance violations in: {violations}')
              with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
                  f.write('has_violations=true\n')
              exit(1)
          print('‚úÖ All modules compliant')
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write('has_violations=false\n')
          "

      - name: Comment summary on PR
        if: steps.check_violations.outputs.has_violations == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            try {
              const r = JSON.parse(fs.readFileSync('compliance_report.json', 'utf8'));
              const mod = r.compliance_summary || {};
              const lines = ['### üìä Docs Compliance Check'];
              for (const [k,v] of Object.entries(mod)) {
                lines.push(`- **${k}**: ${v.ok ? '‚úÖ OK' : '‚ùå ' + (v.violations?.join(', ') || 'violations')}`);
              }
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: lines.join('\n')
              });
            } catch(e) {
              console.log('Failed to parse compliance report:', e);
            }